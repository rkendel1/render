# OpenAI-compatible Proxy / vLLM Configuration
# API key for the proxy provider (e.g. NUWA, self-hosted vLLM, etc.)
OPENAI_API_KEY=sk-your-key-here

# Base URL of the OpenAI-compatible endpoint â€” MUST include /v1
# NUWA proxy:  https://api.nuwaapi.com/v1  (default)
# DeepSeek:    https://api.deepseek.com/v1
# vLLM:        http://localhost:8000/v1
# OpenAI:      https://api.openai.com/v1
OPENAI_BASE_URL=https://api.nuwaapi.com/v1

# Model to use (must be supported by the chosen provider)
# NUWA / OpenAI examples: gpt-4o-mini, gpt-4o
# vLLM example:           meta-llama/Llama-3-8b-instruct
AI_MODEL=gpt-4o-mini
